{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import nltk\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(path):\n",
    "    file=open(path,'r',encoding=\"utf-8\")\n",
    "    train=file.readlines()\n",
    "    file.close()\n",
    "    context=[]\n",
    "    utter=[]\n",
    "    label=[]\n",
    "    for i in train:\n",
    "        c,u,l=i.split('\\t')\n",
    "        context.append(c.strip().split())\n",
    "        utter.append(u.strip().split())\n",
    "        label.append(int(l.strip()))\n",
    "    return context,utter,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_train,utter_train,label_train=input_data(\"chatbot/WikiQA-train.txt\")\n",
    "context_test,utter_test,label_test=input_data(\"WikiQACorpus/WikiQACorpus/WikiQA-test.txt\")\n",
    "context_valid,utter_valid,label_valid=input_data(\"WikiQACorpus/WikiQACorpus/WikiQA-dev.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train=np.array(label_train,dtype='float32')\n",
    "label_test=np.array(label_test,dtype='float32')\n",
    "label_valid=np.array(label_valid,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9489194499017681\n"
     ]
    }
   ],
   "source": [
    "o=0\n",
    "for i in label_train:\n",
    "    if i==0:\n",
    "        o+=1\n",
    "print(o/len(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,a,l=input_data(\"WikiQACorpus/WikiQACorpus/WikiQA-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'partly',\n",
       " 'submerged',\n",
       " 'glacier',\n",
       " 'cave',\n",
       " 'on',\n",
       " 'Perito',\n",
       " 'Moreno',\n",
       " 'Glacier',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_index(sentence,utter,sv,uv,st,ut):\n",
    "    wordindex={}\n",
    "    k=0\n",
    "    train_words=sentence+utter+sv+uv+st+ut\n",
    "    for sent in tqdm(train_words):\n",
    "        for t in sent:\n",
    "            if t not in wordindex.keys():\n",
    "                wordindex[t]=k\n",
    "                k+=1\n",
    "            else:\n",
    "                continue\n",
    "    print(len(wordindex.keys()))\n",
    "    return wordindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58516/58516 [00:00<00:00, 374788.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_dict=word_index(context_train,utter_train,context_test,context_valid,utter_test,utter_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_utt_len(sentence):\n",
    "    maxi=0\n",
    "    for i in sentence:\n",
    "        maxi=max(len(i),maxi)\n",
    "    return maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_utt_len(utter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(utter_train)):\n",
    "    if len(utter_train[i])>150:\n",
    "        utter_train[i]=utter_train[i][:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordtoindex(sentences,d):\n",
    "    for sent in tqdm(sentences):\n",
    "        for i in range(len(sent)):\n",
    "            sent[i]=d[sent[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=fasttext.train_unsupervised('WikiQACorpus/WikiQACorpus/WikiQA-train.txt','cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=list(model.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Beretta' in ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector(ls[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_vec_dict={}\n",
    "for i in range(len(ls)):\n",
    "    id_to_vec_dict[i]=model.get_word_vector(ls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14358"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_vec_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index={i:k for k,i in enumerate(ls)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13796"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['Beretta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20360 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'beretta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-82709d8e0625>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwordtoindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwordtoindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutter_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwordtoindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwordtoindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutter_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwordtoindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-7e0dc1abff76>\u001b[0m in \u001b[0;36mwordtoindex\u001b[1;34m(sentences, d)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'beretta'"
     ]
    }
   ],
   "source": [
    "wordtoindex(context_train,word_to_index)\n",
    "wordtoindex(utter_train,word_to_index)\n",
    "wordtoindex(context_test,word_to_index)\n",
    "wordtoindex(utter_test,word_to_index)\n",
    "wordtoindex(context_valid,word_to_index)\n",
    "wordtoindex(utter_valid,word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix(sentence,max_len):\n",
    "    mask=[]\n",
    "    for i in tqdm(range(len(sentence))):\n",
    "        mask.append([1 for i in range(len(sentence[i]))])\n",
    "        for j in range(max_len-len(sentence[i])):\n",
    "            sentence[i].append(0)\n",
    "            mask[i].append(0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20360/20360 [00:00<00:00, 28276.44it/s]\n",
      "100%|██████████| 20360/20360 [00:00<00:00, 104315.66it/s]\n",
      "100%|██████████| 6165/6165 [00:00<00:00, 21652.84it/s]\n",
      "100%|██████████| 6165/6165 [00:00<00:00, 90908.68it/s]\n",
      "100%|██████████| 2733/2733 [00:00<00:00, 18942.53it/s]\n",
      "100%|██████████| 2733/2733 [00:00<00:00, 77426.77it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_utter_train=matrix(utter_train,max_utt_len(utter_train))\n",
    "mask_sentence_train=matrix(context_train,max_utt_len(context_train))\n",
    "mask_utter_test=matrix(utter_test,max_utt_len(utter_test))\n",
    "mask_sentence_test=matrix(context_test,max_utt_len(context_test))\n",
    "mask_utter_valid=matrix(utter_valid,max_utt_len(utter_valid))\n",
    "mask_sentence_valid=matrix(context_valid,max_utt_len(context_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_train=np.array(context_train)\n",
    "\n",
    "utter_test=np.array(utter_test)\n",
    "\n",
    "context_test=np.array(context_test)\n",
    "\n",
    "utter_valid=np.array(utter_valid)\n",
    "\n",
    "context_valid=np.array(context_valid)\n",
    "\n",
    "mask_utter_train=np.array(mask_utter_train)\n",
    "\n",
    "mask_sentence_train=np.array(mask_sentence_train)\n",
    "\n",
    "mask_utter_test=np.array(mask_utter_test)\n",
    "\n",
    "mask_sentence_test=np.array(mask_sentence_test)\n",
    "\n",
    "mask_utter_valid=np.array(mask_utter_valid)\n",
    "\n",
    "mask_sentence_valid=np.array(mask_sentence_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_train=np.array(utter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20360, 150)\n",
      "(20360, 150)\n",
      "(20360, 23)\n",
      "(20360, 23)\n",
      "(6165, 112)\n",
      "(6165, 112)\n",
      "(6165, 21)\n",
      "(6165, 21)\n",
      "(2733, 132)\n",
      "(2733, 132)\n",
      "(2733, 24)\n",
      "(2733, 24)\n"
     ]
    }
   ],
   "source": [
    "print(utter_train.shape)\n",
    "print(mask_utter_train.shape)\n",
    "print(context_train.shape)\n",
    "print(mask_sentence_train.shape)\n",
    "print(utter_test.shape)\n",
    "print(mask_utter_test.shape)\n",
    "print(mask_sentence_test.shape)\n",
    "print(context_test.shape)\n",
    "print(utter_valid.shape)\n",
    "print(mask_utter_valid.shape)\n",
    "print(context_valid.shape)\n",
    "print(mask_sentence_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:19<00:00, 20203.20it/s]\n"
     ]
    }
   ],
   "source": [
    "file=open(\"glove.6B.50d.txt\",'r',encoding=\"utf-8\")\n",
    "wordembeds=file.readlines()\n",
    "file.close()\n",
    "glove_embeds={}\n",
    "for i in tqdm(wordembeds):\n",
    "    ls=i.strip().split()\n",
    "    for i in range(1,len(ls)):\n",
    "        ls[i]=float(ls[i])\n",
    "    glove_embeds[ls[0]]=ls[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_glove(id_dict,glove_embeds):\n",
    "    id_to_glove={}\n",
    "    for word,embed in glove_embeds.items():\n",
    "        if word in id_dict:\n",
    "            id_to_glove[id_dict[word]]=np.array(embed,dtype='float32')\n",
    "    for word,ind in id_dict.items():\n",
    "        if ind not in id_to_glove:\n",
    "            vec=np.zeros(50,dtype='float32')\n",
    "            vec[:]=np.random.randn(50)*0.01\n",
    "            id_to_glove[ind]=vec\n",
    "    return id_to_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_id_glove=id_to_glove(words_dict,glove_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customdataloader(torch.utils.data.Dataset):\n",
    "    def __init__(self,sent,utter,lab,sent_mask,utter_mask):\n",
    "        self.sent=sent\n",
    "        self.utter=utter\n",
    "        self.lab=lab\n",
    "        self.sent_mask=sent_mask\n",
    "        self.utter_mask=utter_mask\n",
    "    def __len__(self):\n",
    "        return len(self.lab)\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.sent[idx],self.utter[idx],self.lab[idx],self.sent_mask[idx],self.utter_mask[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,Dictionary,word_embedding_length=50):\n",
    "        super(Net,self).__init__()\n",
    "        self.Dictionary=Dictionary\n",
    "        self.lenDictionary=len(Dictionary)\n",
    "        self.word_embedding_length=word_embedding_length\n",
    "        self.embedding=nn.Embedding(self.lenDictionary,self.word_embedding_length)\n",
    "        self.rnnBlock=nn.Linear(self.word_embedding_length*2,self.word_embedding_length*2)\n",
    "        self.lstmBlock=nn.LSTM(self.word_embedding_length,self.word_embedding_length)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #init.uniform(self.lstmBlock.weight_ih_l0,a=-0.01,b=0.01)\n",
    "        #init.orthogonal(self.lstmBlock.weight_hh_l0)\n",
    "        #self.lstmBlock.weight_ih_l0.requires_grad=True\n",
    "        #self.lstmBlock.weight_hh_l0.requires_grad=True\n",
    "        \n",
    "        embedding_weights=torch.FloatTensor(self.lenDictionary,self.word_embedding_length)\n",
    "        for idx,glove in self.Dictionary.items():\n",
    "            embedding_weights[idx]=torch.FloatTensor(list(glove))\n",
    "        self.embedding.weight=nn.Parameter(embedding_weights,requires_grad=True)\n",
    "        self.embedding=nn.Embedding.from_pretrained(self.embedding.weight)\n",
    "    \n",
    "    def forward(self,sent,masksent):\n",
    "        out_sent=self.forwardLSTM(sent,masksent)\n",
    "        #M=torch.FloatTensor(50,50)\n",
    "        #init.xavier_normal(M)\n",
    "        #self.M=nn.Parameter(M,requires_grad=True)\n",
    "        #context=out_sent.mm(self.M)\n",
    "        #context=context.view(-1,1,50)\n",
    "        #response=out_utt.view(-1,50,1)\n",
    "        #dotprod=torch.bmm(context,response).view(-1,1)\n",
    "        #dotprod=[]\n",
    "        #for i in range(len(out_sent)):\n",
    "            #dotprod.append(out_sent[i].dot(out_utt[i]))\n",
    "        return out_sent\n",
    "    def forwardRNN(self,utt,mask):\n",
    "        hidden=torch.zeros([utt.shape[0],self.word_embedding_length]).to(utt.device)\n",
    "        output=torch.zeros([utt.shape[0],self.word_embedding_length]).to(utt.device)\n",
    "        for no,(utti,maski) in enumerate(zip(utt,mask)):\n",
    "            utti_embedding=self.embedding(utti)\n",
    "            for noj,(uttij,maskij) in enumerate(zip(utti_embedding,maski)):\n",
    "                if maskij==0:\n",
    "                    break\n",
    "                temp=self.rnnBlock(torch.cat([uttij,hidden[no]]).unsqueeze(0))[0]\n",
    "                hidden[no]=F.relu(temp[self.word_embedding_length:])\n",
    "                output[no]=temp[:self.word_embedding_length]\n",
    "        return output\n",
    "    def forwardLSTM(self,utt,mask):\n",
    "        output=torch.zeros([utt.shape[0],self.word_embedding_length]).to(utt.device)\n",
    "        for no,(utti,maski) in enumerate(zip(utt,mask)):\n",
    "            utti_embed=self.embedding(utti)\n",
    "            numutt=torch.sum(maski)\n",
    "            utti_embed=utti_embed[:numutt].unsqueeze(1)\n",
    "            _,(last_hidden,_)=self.lstmBlock(utti_embed)\n",
    "            last_hidden=self.dropout(last_hidden[0][0])\n",
    "            output[no]=last_hidden\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer,epoch):\n",
    "    model.train()\n",
    "    for batchid,(sent,utt,lab,masksent,maskutt) in tqdm(enumerate(train_loader)):\n",
    "        correct=0\n",
    "        optimizer.zero_grad()\n",
    "        output_sent=model(sent,masksent)\n",
    "        output_utt=model(utt,maskutt)\n",
    "        loss=0\n",
    "        for i in range(len(output_sent)):\n",
    "            loss+=(output_sent[i].dot(output_utt[i])/(torch.norm(output_sent[i])*torch.norm(output_utt[i]))-lab[i])**2\n",
    "        loss/=len(output_sent)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batchid % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batchid * len(sent), len(train_loader.dataset),\n",
    "            100. * batchid / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,valid_loader):\n",
    "    model.eval()\n",
    "    validloss=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for batchid,(sent,utt,lab,masksent,maskutt) in enumerate(valid_loader):\n",
    "            output_utt=model(utt,maskutt)\n",
    "            output_sent=model(sent,masksent)\n",
    "            for i in range(len(output_sent)):\n",
    "                validloss+=(output_sent[i].dot(output_utt[i])/(torch.norm(output_sent[i])*torch.norm(output_utt[i]))-lab[i])**2\n",
    "                if int(output_sent[i].dot(output_utt[i])+0.5)==lab[i]:\n",
    "                    correct+=1\n",
    "            validloss/=len(output_sent)\n",
    "            print(validloss,100*correct/len(valid_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed_value):\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "    torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    seed(0)\n",
    "    train_data=customdataloader(context_train,utter_train,label_train,mask_sentence_train,mask_utter_train)\n",
    "    test_data=customdataloader(context_test,utter_test,label_test,mask_sentence_test,mask_utter_test)\n",
    "    valid_data=customdataloader(context_valid,utter_valid,label_valid,mask_sentence_valid,mask_utter_valid)\n",
    "    train_loader=DataLoader(train_data,num_workers=0,batch_size=40,shuffle=False)\n",
    "    test_loader=DataLoader(test_data,num_workers=0,batch_size=1000,shuffle=False)\n",
    "    valid_loader=DataLoader(valid_data,num_workers=0,batch_size=1000,shuffle=False)\n",
    "    model=Net(words_id_glove)\n",
    "    optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "    #model.load_state_dict(torch.load(\"wikiqa.pt\"))\n",
    "    for epoch in range(1,2):\n",
    "        train(model,train_loader,optimizer,epoch)\n",
    "        validation(model,valid_loader)\n",
    "    validation(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/20360 (0%)]\tLoss: 0.165608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [01:16,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4000/20360 (20%)]\tLoss: 0.102786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [02:29,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8000/20360 (39%)]\tLoss: 0.061891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [03:42,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12000/20360 (59%)]\tLoss: 0.192049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [04:54,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [16000/20360 (79%)]\tLoss: 0.088637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [06:09,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [20000/20360 (98%)]\tLoss: 0.039670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "509it [06:15,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0748) 35.27259421880717\n",
      "tensor(0.0985) 69.30113428466886\n",
      "tensor(0.1102) 94.18221734357849\n",
      "tensor(0.0981) 15.279805352798054\n",
      "tensor(0.0860) 30.721816707218167\n",
      "tensor(0.1130) 45.790754257907544\n",
      "tensor(0.0980) 61.15166261151663\n",
      "tensor(0.0997) 76.44768856447689\n",
      "tensor(0.0859) 91.92214111922141\n",
      "tensor(0.0994) 94.42011354420113\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s,words_dict):\n",
    "    mask=[[]]\n",
    "    ls=[[]]\n",
    "    ls[0]=s.split()\n",
    "    i=0\n",
    "    n=len(ls[0])\n",
    "    while i<n:\n",
    "        if ls[0][i] in words_dict:\n",
    "            ls[0][i]=words_dict[ls[0][i]]\n",
    "            mask[0].append(1)\n",
    "            i+=1\n",
    "        else:\n",
    "            ls[0].pop(i)\n",
    "            n-=1\n",
    "    ls=np.array(ls)\n",
    "    mask=np.array(mask)\n",
    "    return ls,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:55<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "source": [
    "model=Net(words_id_glove)\n",
    "model.load_state_dict(torch.load(\"wikiqafinal.pt\"))\n",
    "train_data=customdataloader(context_train,utter_train,label_train,mask_sentence_train,mask_utter_train)\n",
    "train_loader=DataLoader(train_data,num_workers=0,batch_size=1000,shuffle=False)\n",
    "ls_utt=[]\n",
    "with torch.no_grad():\n",
    "    for (sent,utt,lab,masksent,maskutt) in tqdm(train_loader):\n",
    "        output=model(utt,maskutt)\n",
    "        ls_utt.extend(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ls_utt)):\n",
    "    ls_utt[i]=ls_utt[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2=open(\"answer_embeds(1).pkl\",'ab')\n",
    "pickle.dump(ls_utt,file2)\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "tensor([[-0.0000e+00,  0.0000e+00, -8.5996e-02,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  3.0250e-02,  0.0000e+00, -1.2950e-01,\n",
      "          2.1869e-02, -8.1768e-02, -1.0104e-01,  0.0000e+00,  0.0000e+00,\n",
      "         -1.5226e-01,  2.4174e-02, -2.6548e-02,  1.4127e-01, -2.0230e-02,\n",
      "         -0.0000e+00, -9.2644e-02, -4.0494e-02, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00, -3.7603e-02, -0.0000e+00, -0.0000e+00,\n",
      "         -1.8482e-04, -0.0000e+00, -0.0000e+00,  1.0619e-01,  0.0000e+00,\n",
      "          0.0000e+00,  1.0109e-03,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -9.1154e-02,  4.3980e-02,  8.7051e-02, -1.2229e-01,\n",
      "         -9.0598e-02, -2.6327e-01, -0.0000e+00,  9.9694e-02,  0.0000e+00]])\n",
      "15621\n",
      "tensor(1.0664)\n"
     ]
    }
   ],
   "source": [
    "s='how did appolo creed die'\n",
    "with torch.no_grad():\n",
    "    q , qm = preprocess(s,words_dict)\n",
    "    q=torch.from_numpy(q)\n",
    "    qm=torch.from_numpy(qm)\n",
    "    print(q.shape)\n",
    "    print(qm.shape)\n",
    "    output_q=model(q,qm)\n",
    "    print(output_q)\n",
    "    arg_max=-1\n",
    "    dot_prod=-1\n",
    "    for idx,m in enumerate(ls_utt):\n",
    "        if output_q[0].dot(m)>dot_prod:\n",
    "            dot_prod=output_q[0].dot(m)\n",
    "            arg_max=idx\n",
    "    print(arg_max)\n",
    "    print(output_q[0].dot(ls_utt[arg_max]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Information', 'and', 'Communications', 'Technology', 'or', '(', 'ICT', ')', ',', 'is', 'often', 'used', 'as', 'an', 'extended', 'synonym', 'for', 'information', 'technology', '(', 'IT', ')', ',', 'but', 'is', 'a', 'more', 'specific', 'term', 'that', 'stresses', 'the', 'role', 'of', 'unified', 'communications', 'and', 'the', 'integration', 'of', 'telecommunications', '(', 'telephone', 'lines', 'and', 'wireless', 'signals', ')', ',', 'computers', 'as', 'well', 'as', 'necessary', 'enterprise', 'software', ',', 'middleware', ',', 'storage', ',', 'and', 'audio-visual', 'systems', ',', 'which', 'enable', 'users', 'to', 'access', ',', 'store', ',', 'transmit', ',', 'and', 'manipulate', 'information', '.']\n"
     ]
    }
   ],
   "source": [
    "print(a[7716])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
